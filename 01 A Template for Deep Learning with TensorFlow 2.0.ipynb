{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 A Template for Deep Learning with TensorFlow 2.0\n",
    "## Dr. Tristan Behrens\n",
    "\n",
    "In the following we will solve the Hello World of Machine Learning and Computer Vision: MNIST.\n",
    "\n",
    "This notebook has a couple of purposes:\n",
    "- introducing you to the world of Deep Learning,\n",
    "- explaining the key concepts, and\n",
    "- acting as a template for all your future projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that we have TensorFlow 2 enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary modules  and check TensorFlow version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith(\"2.\"), \"You have TensorFlow version {}, 2.X is required, please upgrade.\".format(tf.__version__)\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split MNIST-dataset.\n",
    "\n",
    "The MNIST dataset is a fine example for Supervised Learning. In Supervised Learning you have labeled data. That is, for each input sample, you have an expected output. This is usually called label or target.\n",
    "\n",
    "We split the data into tree subsets:\n",
    "- Train: For training the Neural Network.\n",
    "- Validate: To see how good the Neural Network is after each epoch.\n",
    "- Test: To see how good the Neural Network is after training.\n",
    "\n",
    "It is a general practice to have at least validate. Ideally, you would also have test, but some people do not use a test set at all.\n",
    "\n",
    "Link: [MNIST database](https://www.google.com/search?client=safari&rls=en&q=mnist&ie=UTF-8&oe=UTF-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train, mnist_validate, mnist_test), info = tfds.load(\n",
    "    name=\"mnist\", \n",
    "    split=[\"train[:80%]\", \"train[80%:]\", \"test\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "print(\"Train:   \", len(list(mnist_train)))\n",
    "print(\"Validate:\", len(list(mnist_validate)))\n",
    "print(\"Test:    \", len(list(mnist_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at your data!\n",
    "\n",
    "Never trust the source of your data. Even if you created it. Do not worry, this is not paranoia. It is just a good way how to ensure the quality of your project. Always look at your data, because most of the times if there is something not so nice, the data is the cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "plt.figure(figsize=(20, 2))\n",
    "for mnist_example in mnist_train.take(6):\n",
    "    image, label = mnist_example\n",
    "\n",
    "    plt.subplot(1, 6, index)\n",
    "    plt.imshow(image.numpy()[:, :, 0], cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.title(\"Label: {}\".format(label.numpy()))\n",
    "    index += 1\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the datasets with tf.data.\n",
    "\n",
    "You can build very efficient input pipelines for your datasets with tf.data. Here we will use it for two things:\n",
    "- Converting the images to floating point numbers and normalizing the data, and\n",
    "- map the labels to a so called one hot encoding.\n",
    "\n",
    "Link: [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(image, label):\n",
    "    image_encoded = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    label_encoded = tf.one_hot(label, depth=10)\n",
    "    return image_encoded, label_encoded\n",
    "\n",
    "mnist_train = mnist_train.map(lambda image, label: encode(image, label))\n",
    "mnist_validate = mnist_validate.map(lambda image, label: encode(image, label))\n",
    "mnist_test = mnist_test.map(lambda image, label: encode(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A second look at our data.\n",
    "\n",
    "While the images just got normalized, the labels now have a so called one-hot encoding. There is empirical (but no mathematical proof) that normalizing (or standardizing) input data improves training in Deep Learning. One-hot encodings are nice. They encode our labels as a perfect probability distribution over our classes, in our case digits. Many zeros, only one one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "plt.figure(figsize=(20, 2))\n",
    "for mnist_example in mnist_train.take(6):\n",
    "    image, label = mnist_example\n",
    "\n",
    "    plt.subplot(1, 6, index)\n",
    "    plt.imshow(image.numpy()[:, :, 0], cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.title(\"Label:\\n {}\".format(label.numpy()))\n",
    "    index += 1\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Deep Neural Network to solve our classification problem - Multi-Layer Perceptron.\n",
    "\n",
    "Not that the data pipeline is up and running, we can create our Neural Network. We will use a Multi-Layer perceptron. It is a rather traditional but reliable ANN. In its essence, it is a fully connected network with multiple Hidden layers.\n",
    "\n",
    "One way to create Neural Networks in TensorFlow 2 is the so called Sequential API. Sequential models have one input, one output and multiple hidden layers. If you need more, you could also use the Functional API or Mode subclassing. We will discuss this in the future.\n",
    "\n",
    "Note below, that input and output sizes are determined by the data. Hidden layers are variable both in amount and sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flatten layer reshapes the 2D images into 1D array. This is reversible, no information is lost.\n",
    "\n",
    "Dense layers are fully connected layers. The fist layer has ReLU (Rectified Linear Unit) as a so called activation function. We will talk about activation functions later.\n",
    "\n",
    "The final layer has a softmax activation function. This function makes sure that all 10 numbers in the output are between 0.0 and 1.0, while their sum is 1.0. This basically ensures that the output is a probability distribution. Remember: Our labels are one-hot encoding, perfect probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach optimizer, loss, and metrics.\n",
    "\n",
    "In order to train an ANN, we need a couple of components:\n",
    "\n",
    "- The optimizer is the training algorithm that changes the trainable parameters of an ANN in order to solve the given problem. We use RMSprop. RMSprop is always a good start.\n",
    "- The loss function computes the error between the outputs predicted by the ANN and the outputs we expect in supervised learning. Here we use Categorical Crossentropy. It is great at computing the error between two probability distributions. The optimizer uses the loss function in order to optimize the Neural Network.\n",
    "- Metrics are optional. They can be considered losses that are only used by humans. The optimizer does not consider metrics. Here we use accuracy. It tells us how many predictions are right. Works like a charm for classifiers.\n",
    "\n",
    "In the future we will talk about optimizers and losses in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is our ANN before training?\n",
    "\n",
    "Before training, we should have a look at how good our Neural Network is. Note that we do not expect our randomly initialized Neural Network to be any good.\n",
    "\n",
    "Let us consider a single sample first to get an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_example = list(mnist_test.take(1).as_numpy_iterator())[0]\n",
    "\n",
    "image, label = mnist_example\n",
    "prediction = model.predict(np.array([image]))\n",
    "plt.plot(prediction[0], label=\"Prediction\")\n",
    "plt.plot(label, label=\"Expectation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our prediction (blue) is not anywhere close to what whe expect (orange). Ideally both plots would be identical. The \"difference\" between blue and orange is our loss.\n",
    "\n",
    "It would be interesting to see how good the Neural Network is when it comes to the entire dataset. In order to find out, we evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(mnist_test.batch(32), verbose=0)\n",
    "print(\"Loss: {}\".format(loss))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just focus on accuracy, we see that it is around 10% (+-). It tells us that our Neural Network is right in about that percentage of all predictions on the test set. A random baseline would be 10%. The accuracy is really bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN training.\n",
    "\n",
    "Now we know how good (bad) our Neural Network is. We have everything ready. Including the data, network architecture, the optimizer, and the loss.\n",
    "\n",
    "We can train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    mnist_train.batch(128),\n",
    "    epochs=5,\n",
    "    validation_data=mnist_validate.batch(128)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train for 5 epochs. This means that we will apply the optimizer on the entire training dataset five times. For each epoch we use a batch size of 128. Be do not train on a single image-label-pair per step. Instead we speed up training by training on multiple samples in parallel.\n",
    "\n",
    "Also we will use the validation data, to check how good our Neural Network is on data that is not in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the history.\n",
    "\n",
    "The above log is quite nice. In your future projects it will be rather unreadable. It is a best-practice to visualize the training. A picture is way more expressive than the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Metrics\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see here? Our optimizer manages to get the loss down. It is rather natural that the loss goes down for the training set. The optimizer directly works with that data. But that the loss also goes down for the validation set is something that we want to achieve:\n",
    "\n",
    "In summary:\n",
    "- The training loss shows us how well the Neural Network is capable of solving the problem, how well it optimizes.\n",
    "- The validation loss shows us how well the Neural Network is capable of working with data it has not been trained on, how well in generalizes.\n",
    "\n",
    "Our accuracy, shows a similar picture. It goes up for both our dataset. For the validation set it almost reaches 98%. Sweet success!\n",
    "\n",
    "How to read such and similar plots will be a future topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is our ANN after training?\n",
    "\n",
    "After training we will do the same excercise that we did before training.\n",
    "\n",
    "How good is our Neural Network with one sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_example = list(mnist_test.take(1).as_numpy_iterator())[0]\n",
    "\n",
    "image, label = mnist_example\n",
    "prediction = model.predict(np.array([image]))\n",
    "plt.plot(prediction[0], label=\"Prediction\")\n",
    "plt.plot(label, label=\"Expectation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! We do not see the blue plot because it is hidden behind the orange one. Note that the sample came from the test stet. Thus the Neural Network never saw it during training.\n",
    "\n",
    "Finally, we evaluate the Neural Network using the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(mnist_test.batch(32), verbose=0)\n",
    "print(\"Loss: {}\".format(loss))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see! Now the numbers are way better. The loss is down and the accuracy is up. Well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model.\n",
    "\n",
    "After training you can save your model and deploy it. And if you like, write your customer and invoice or publish a research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary.\n",
    "\n",
    "The above code is a template for all your Deep Learning projects. You will have all the components. You might have a different way of data preprocessing, different hyperparameters and Neural Network architectures. But always you will have the same pattern.\n",
    "\n",
    "Thank you so much for learning. Keep an eye out for more. And if there is a topic that I did not cover, let me know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
